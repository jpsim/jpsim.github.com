<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: ios | JP Simard]]></title>
  <link href="https://jpsim.com/categories/ios/atom.xml" rel="self"/>
  <link href="https://jpsim.com/"/>
  <updated>2026-01-02T19:54:14+00:00</updated>
  <id>https://jpsim.com/</id>
  <author>
    <name><![CDATA[JP Simard]]></name>
    <email><![CDATA[jp@jpsim.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Building an NFC Music Box]]></title>
    <link href="https://jpsim.com/building-an-nfc-music-box/"/>
    <updated>2023-03-31T11:00:00+00:00</updated>
    <id>https://jpsim.com/building-an-nfc-music-box</id>
    <content type="html"><![CDATA[<p>My son and I built an NFC-based music player so he can play the music he
wants, develop his own musical taste but most of all so that he and I
could have something fun to build together.</p>

<p>Kind of like a modern day record player, but infinitely more extensible,
and with each album costing 1/100th the price of a vinyl record.</p>

<p>Here it is in action (<em>music starts 9 seconds into the video, set your
volume to low</em>):</p>

<iframe title="vimeo-player" src="https://player.vimeo.com/video/813573763?h=6b3ebec0bc" width="640" height="360" frameborder="0" allowfullscreen></iframe>


<p><br /></p>

<p>And here's how we built it:</p>

<h2>Materials</h2>

<table>
<thead>
<tr>
<th><br /></th>
<th><br /></th>
<th><br /></th>
<th><br /></th>
<th><br /></th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="/images/posts/musicbox/echo.jpg" alt="" /></td>
<td><img src="/images/posts/musicbox/case.jpg" alt="" /></td>
<td><img src="/images/posts/musicbox/pi.jpg" alt="" /></td>
<td><img src="/images/posts/musicbox/nfc_module.jpg" alt="" /></td>
<td><img src="/images/posts/musicbox/nfc_cards.jpg" alt="" /></td>
</tr>
</tbody>
</table>


<ul>
<li><a href="https://www.amazon.com/dp/B08YT3BWMP">Amazon Echo Dot, $20</a>:
For the price, this is a surprisingly hackable, portable speaker. I would have
prefered something without any microphones at all, but I <em>mostly</em> trust the
hardware mute switch.</li>
<li><a href="https://www.etsy.com/listing/739034156">Case, $20</a>: Beautiful
retro-style case for the Raspberry Pi. The top compartment is made to
house a fan, but this is where I put the NFC module instead. The folks
who make this at <a href="https://twitter.com/theC4Labs">C4 Labs</a> were <a href="https://twitter.com/simjp/status/1259980961665576960">super nice</a>.
We broke a piece when we started building the box and they sent a
replacement part right away.</li>
<li><a href="https://www.raspberrypi.org/products/raspberry-pi-4-model-b/">Raspberry Pi, $35</a>:
I chose to go with a Raspberry Pi because they're cheap, have good
compatible NFC modules, lots of case options on Etsy and easy to
develop on.</li>
<li><a href="https://www.amazon.com/dp/B01CSTW0IA">NFC Module, $5</a>: I can't
believe this thing is just $5. Works great. Lots of good tutorials on
connecting this to a Raspberry Pi.</li>
<li><a href="https://store.gototags.com/nfc-pvc-card-ntag213/">NFC Cards, $29</a>:
I got 100 cards at $0.29 each.</li>
</ul>


<p>In total, this adds up to $109, but in my case I already had a Raspberry
Pi and an Echo Dot lying around that I could repurpose for this, so it
cost me closer to $55.</p>

<h2>Services</h2>

<p>I'm already an Apple Music subscriber, so using that as the music source
was the cheapest solution, although this setup would work with any music
service that works with Amazon Echo: Spotify, Amazon Music, TuneIn,
CloudPlayer, Deezer, iHeartRadio.</p>

<p>In the exploration phase for this project, I wanted to buy DRM-free
music, wire a speaker directly to the Raspberry Pi and play it locally.
However, that would have meant that adding music later would be a much
more tedious task. Plus it's hard to find DRM-free music these days, and
when you do find what you want it ends up being pricey. Especially
compared to the convenience and cost of today's streaming options.</p>

<p>I also explored using HomePods as the speakers (see addendum below).</p>

<p>The biggest downside to the current streaming approach is that there's a
5-10 second delay after tapping a card and music starting.</p>

<h2>Assembly</h2>

<table>
<thead>
<tr>
<th><br /></th>
<th><br /></th>
<th><br /></th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="/images/posts/musicbox/assembly1.jpg" alt="Assembly #1" /></td>
<td><img src="/images/posts/musicbox/assembly2.jpg" alt="Assembly #2" /></td>
<td><img src="/images/posts/musicbox/assembly3.jpg" alt="Assembly #3" /></td>
</tr>
<tr>
<td><img src="/images/posts/musicbox/assembly4.jpg" alt="Assembly #4" /></td>
<td><img src="/images/posts/musicbox/assembly5.jpg" alt="Assembly #5" /></td>
<td><img src="/images/posts/musicbox/assembly6.jpg" alt="Assembly #6" /></td>
</tr>
</tbody>
</table>


<p><br /></p>

<p>I assembled this with my son over a few days in May 2020, and then
finished the setup in September 2021. The actual hardware assembly
probably only took a combined total of 3 hours though.</p>

<h2>Software</h2>

<p><em>Disclaimer: This code is rough, it's suitable for a toy project. I'm
sharing it in case it's useful for others getting started with a similar,
project. I'm not claiming this is beautiful quality code.</em></p>

<h3>Echo Dot Remote Control</h3>

<p>I use the <a href="https://github.com/thorsten-gehrig/alexa-remote-control">alexa-remote-control</a> shell script to
control the Echo Dot. When it's up and running, it couldn't be easier:</p>

<pre><code class="shell">$ alexa_remote_control.sh -e "playmusic:APPLE_MUSIC:The Lion King"
$ alexa_remote_control.sh -e pause
$ alexa_remote_control.sh -e play
$ alexa_remote_control.sh -e vol:15
</code></pre>

<h3>NFC Reader</h3>

<p>I use <a href="https://github.com/pelwell/MFRC522-python">MFRC522-python</a> to
interface with the NFC module.</p>

<p>The Python script that reads cards and plays music looks like this:</p>

<pre><code class="python">import RPi.GPIO as GPIO
import MFRC522
import os
import signal

continue_reading = True
last_seen_card = None
echo_name = "MusicBox Echo"
current_dir = os.path.dirname(os.path.abspath(__file__))
alexa_control_script = os.path.join(current_dir, "alexa_remote_control.sh")

def alexa(command):
    os.system(
        '{alexa_control_script} -d "{echo_name}" -e "{command}"'.format(
            alexa_control_script=alexa_control_script,
            echo_name=echo_name,
            command=command,
        )
    )

def pause():
    alexa("pause")

def play_music(query):
    print(query)
    pause()
    alexa("playmusic:APPLE_MUSIC:{query}".format(query=query))

def set_volume(volume):
    alexa("vol:{volume}".format(volume=volume))

def end_read(signal, frame):
    global continue_reading
    continue_reading = False
    GPIO.cleanup()

signal.signal(signal.SIGINT, end_read)

MIFAREReader = MFRC522.MFRC522()

while continue_reading:
    # Scan for cards
    (status, TagType) = MIFAREReader.MFRC522_Request(MIFAREReader.PICC_REQIDL)

    # If we have a card, continue
    if status == MIFAREReader.MI_OK:
        # Get the UID of the card
        (status, uid) = MIFAREReader.MFRC522_Anticoll()

        # If we have the UID, continue
        if status == MIFAREReader.MI_OK and last_seen_card != uid:
            last_seen_card = uid

            # Print UID
            print("Card UID: %s" % uid)
            if uid == [136, 4, 76, 240, 48]:
                print("PAUSE")
                pause()
            elif uid == [136, 4, 236, 236, 140]:
                set_volume(10)
            elif uid == [136, 4, 247, 42, 81]:
                set_volume(40)
            elif uid == [136, 4, 137, 170, 175]:
                play_music("Star Wars A New Hope Soundtrack")
            elif uid == [136, 4, 148, 191, 167]:
                play_music("Paco de Lucia")
            elif uid == [136, 4, 160, 224, 204]:
                play_music("Dexter Gordon")
            elif uid == [136, 4, 197, 238, 167]:
                play_music("Rainbow Connection")
            elif uid == [136, 4, 2, 220, 82]:
                play_music("Genesis")
            elif uid == [136, 4, 232, 57, 93]:
                # and so on...
</code></pre>

<p>You'll notice that there are special cards for pausing, setting a high
volume and setting a low volume. The rest of the cards map to music.</p>

<p>The main thing I'd like to improve at some point is to avoid hardcoding
a mapping of the card UIDs to music and instead program it using the
companion iPhone app by writing a payload to the card. The iOS side I
know how to do pretty quickly, but I'd have to spend more time to figure
out how to do it on the MFRC522 reader side of things.</p>

<h3>API Server</h3>

<p>There's an API server that can be used to control the music box using
the companion iPhone app.</p>

<pre><code class="python">from flask import Flask, request, jsonify
import os

api = Flask(__name__)
echo_name = "MusicBox Echo"
current_dir = os.path.dirname(os.path.abspath(__file__))
alexa_control_script = os.path.join(current_dir, "alexa_remote_control.sh")

def alexa(command):
    os.system(
        '{alexa_control_script} -d "{echo_name}" -e "{command}"'.format(
            alexa_control_script=alexa_control_script,
            echo_name=echo_name,
            command=command,
        )
    )

@api.route("/pause", methods=["POST"])
def pause():
    alexa("pause")
    return "{}"

@api.route("/play", methods=["POST"])
def play():
    if request.json:
        play_music(request.json["query"])
    else:
        alexa("play")
    return "{}"

@api.route("/play/&lt;query&gt;", methods=["POST"])
def play_music(query):
    print(query)
    pause
    alexa("playmusic:APPLE_MUSIC:{query}".format(query=query))
    return "{}"

@api.route("/volume/&lt;int:volume&gt;", methods=["POST"])
def set_volume(volume):
    alexa("vol:{volume}".format(volume=volume))
    return "{}"

if __name__ == "__main__":
    api.run(host="0.0.0.0")
</code></pre>

<h3>iPhone App</h3>

<p>Of course I made an iPhone app using <a href="https://developer.apple.com/xcode/swiftui/">SwiftUI</a> &amp;
<a href="https://github.com/pointfreeco/swift-composable-architecture">Composable Architecture</a>.</p>

<p>This helps me quickly adjust the volume, play/pause and play specific
music. If my kid falls alseep to music, I can stop it without having to
walk into his room.</p>

<p>Siri intents work too, so I can play/pause music by speaking to Siri
without having to launch the app.</p>

<p><img src="/images/posts/musicbox/app.jpg" alt="" /></p>

<h2>Closed Source</h2>

<p>Hopefully this post is helpful to someone interested in building
something similar. I've posted enough code and details to get you
started, but I won't be open sourcing the whole project because I'm just
not willing to field support questions or feature requests. I'm happy to
answer questions about my experience building this, but I'm sorry I
can't help you figure out why something's not working if you go build
something similar.</p>

<hr />

<h2>Addendum: HomePod Attempt</h2>

<p>At one point I wanted to use a stereo pair of HomePods for this project,
but all my attempts to reverse engineer a way to play music on them from
a Raspberry Pi were fruitless. I tried sniffing the network traffic via
Charles Proxy while playing music from the iOS Music app or even the
Shortcuts app and wasn't able to crack it. I did end up getting it
working using <a href="https://github.com/owntone/owntone-server">forked-daap</a> but this set the HomePods in a
weird state. I don't remember all the details because I gave up on that
approach for two reasons: the first is that I couldn't get it to work
well and the second is that I wanted to keep the HomePods in our living
room while the music box was meant to be in my son's bedroom.</p>

<hr />
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Uncovering SourceKit]]></title>
    <link href="https://jpsim.com/uncovering-sourcekit/"/>
    <updated>2014-07-06T16:07:00+00:00</updated>
    <id>https://jpsim.com/uncovering-sourcekit</id>
    <content type="html"><![CDATA[<p>To support a <a href="http://developer.apple.com/swift">fancy new language</a>, nifty <a href="https://developer.apple.com/library/prerelease/ios/recipes/xcode_help-source_editor/ExploringandEvaluatingSwiftCodeinaPlayground/ExploringandEvaluatingSwiftCodeinaPlayground.html">realtime IDE</a> features and impressive <a href="https://developer.apple.com/library/prerelease/ios/documentation/Swift/Conceptual/BuildingCocoaApps/InteractingWithObjective-CAPIs.html">cross-language interoperability</a>, Apple had to develop several new underlying tools. Here, we'll focus on <em>SourceKit</em>, Xcode's under-appreciated sidekick.</p>

<p><img src="/images/posts/sidekick.jpg" alt="sidekick" /></p>

<center><sub>SourceKitSidekick temporarily wearing a cape</sub></center>


<p><br/></p>

<h2>What is SourceKit?</h2>

<p>SourceKit is the set of tools that enables most of Swift's source code manipulation features: source code parsing, syntax highlighting, typesetting, autocomplete, cross-language header generation, and lots more.</p>

<h2>Architecture</h2>

<p>Xcode traditionally runs its compiler (<a href="http://clang.llvm.org">Clang</a>) <em>in-process</em>, which means that any time the compiler would crash, so would the IDE.</p>

<p><img src="/images/posts/house_of_cards.jpg" alt="house of cards" /></p>

<center><sub>Xcode architecture diagram</sub></center>


<p><br/></p>

<p>Exacerbating the problem, Xcode can easily invoke the compiler thousands of times to parse, highlight and typeset source code, all before a user ever hits <em>⌘+B</em>. That's because unlike most editors (Vim/Sublime/etc), Xcode doesn't use regular expressions to parse source code, but rather Clang's powerful (though much more complex) parser/tokenizer.</p>

<p>Thankfully, Swift in Xcode 6 moves away from this architecture<sup>1</sup>, combining all these source code manipulation features into a separate process that communicates with Xcode through <a href="https://developer.apple.com/library/mac/documentation/macosx/conceptual/bpsystemstartup/chapters/CreatingXPCServices.html">XPC</a>: <code>sourcekitd</code>. This XPC daemon is launched whenever Xcode 6 loads any Swift code.</p>

<p><img src="/images/posts/sourcekit_terminated.jpg" alt="sourcekit terminated" /></p>

<center><sub>Life would be miserable if Xcode crashed every time this appeared</sub></center>


<p><br/></p>

<h2>How Xcode uses SourceKit</h2>

<p>Since SourceKit is a private and undocumented tool, we need to get a little creative to learn how to use it. By setting the <code>SOURCEKIT_LOGGING</code><sup>2</sup> environment variable, Xcode will log its SourceKit communications to <code>stdout</code>, allowing us to monitor its communications in realtime. This is how many of the commands covered in this article were discovered.</p>

<h2>Unified Symbol Resolution</h2>

<p>SourceKit uses a Clang feature called the USR (Unified Symbol Resolution) as a unique identifier for a source code token (i.e. class, property, method, etc.). This is what allows you to <em>⌘+click</em> any token in Xcode and navigate to its definition. The USR is even more powerful now that it can unify a representation across languages (Swift/ObjC).</p>

<p><img src="/images/posts/usr.jpg" alt="usr" /></p>

<center><sub>The USR at work</sub></center>


<p><br/></p>

<p>To print the USR's from a Swift file (and their locations), you can run the following command:</p>

<pre><code>$ xcrun swift-ide-test -print-usrs -source-filename=Musician.swift
10:7 s:C14swift_ide_test8Musician
14:9 s:vC14swift_ide_test8Musician4nameSS
19:9 s:vC14swift_ide_test8Musician9birthyearSu
33:5 s:FC14swift_ide_test8MusiciancFMS0_FT4nameSS9birthyearSu_S0_
33:10 s:vFC14swift_ide_test8MusiciancFMS0_FT4nameSS9birthyearSu_S0_L_4nameSS
33:24 s:vFC14swift_ide_test8MusiciancFMS0_FT4nameSS9birthyearSu_S0_L_9birthyearSu
34:9 s:vFC14swift_ide_test8MusiciancFMS0_FT4nameSS9birthyearSu_S0_L_4selfS0_
34:21 s:vFC14swift_ide_test8MusiciancFMS0_FT4nameSS9birthyearSu_S0_L_4nameSS
35:9 s:vFC14swift_ide_test8MusiciancFMS0_FT4nameSS9birthyearSu_S0_L_4selfS0_
35:26 s:vFC14swift_ide_test8MusiciancFMS0_FT4nameSS9birthyearSu_S0_L_9birthyearSu
</code></pre>

<h2>Swift<em>ish</em> header generation</h2>

<p><em>⌘+clicking</em> on a token defined in Objective-C from Swift will cause Xcode to trigger a Swift-like header to be generated. I say Swift-like because this generated file is not valid Swift<sup>3</sup>, but at least displays the Swift syntax equivalent to the Objective-C tokens.</p>

<p><a href="/images/posts/generated_swift_header.jpg"><img src="/images/posts/generated_swift_header.jpg" alt="Generated Swift Header" /></a></p>

<center><sub>Left: original Objective-C header. Right: SourceKit-generated Swift-ish version.</sub></center>


<p><br/></p>

<h2>Using SourceKit from the command line</h2>

<p><img src="/images/posts/sourcekit_playground.jpg" alt="SourceKit Playground" /></p>

<p>There are 3 main command line tools that allow to interact with SourceKit: <code>sourcekitd-test</code>, <code>swift-ide-test</code> and <code>swift</code>.</p>

<p>I compiled a shell script with documentation that runs through many useful commands like syntax highlighting, interface generation, AST parsing, demangling, and more.</p>

<p>The script is available on GitHub as a <a href="https://gist.github.com/jpsim/13971c81445219db1c63#file-sourcekit_playground-sh">gist</a>.</p>

<h2>3rd Party Tools Using SourceKit</h2>

<p>Because SourceKit lives outside of Xcode, it’s possible to leverage it to build anything from a Swift IDE to a documentation generator.</p>

<h3>jazzy<sup>♪♫</sup></h3>

<p><img src="/images/posts/jazzy.jpg" alt="jazzy" /></p>

<p><a href="https://github.com/realm/jazzy">jazzy</a> is a command-line utility that generates documentation for your Swift and Objective-C projects. It uses SourceKit to derive Swift syntax from Objective-C defined tokens (i.e. class, property, method, etc.).</p>

<h3>SwiftEdit</h3>

<p><a href="https://github.com/jpsim/SwiftEdit">SwiftEdit</a> is a proof-of-concept editor that supports syntax highlighting for Swift files.</p>

<p><img src="/images/posts/SwiftEdit.png" alt="SwiftEdit" /></p>

<h2>SourceKit &amp; You</h2>

<p>We’re just scratching the surface of what’s possible to build with SourceKit. Tools could be made to measure cross-language code coverage, or provide an editor where Objective-C and Swift can be edited simultaneously. Hopefully this article inspires you to build something with SourceKit and improve our tools in the process.</p>

<hr />

<p><em>1: Objective-C in Xcode 6 (Beta 2) doesn't use SourceKit at all, keeping Xcode's traditional clang-in-process architecture. I expect this to change before Xcode 6 GM.</em></p>

<p><em>2: For SourceKit logging, launch Xcode with <sub><code>export SOURCEKIT_LOGGING=3 &amp;&amp; /Applications/Xcode6-Beta2.app/Contents/MacOS/Xcode</code></sub></em></p>

<p><em>3: Speculation: I expect private Swift modules to expose public interfaces using a similar syntax once the language has <a href="https://github.com/ksm/SwiftInFlux#access-control">access control mechanisms</a>.</em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SF Swift Meetup]]></title>
    <link href="https://jpsim.com/sf-swift-meetup/"/>
    <updated>2014-06-27T14:58:00+00:00</updated>
    <id>https://jpsim.com/sf-swift-meetup</id>
    <content type="html"><![CDATA[<p>I recently gave a talk on <a href="https://developer.apple.com/swift">Swift</a> at the <a href="http://www.meetup.com/swift-language">SF/SV Swift Language User Group</a> meetup. We've made the whole thing available online:</p>

<ul>
<li><a href="http://realm.io/news/swift-unchartered-territory-swift-intro-and-internals">Video</a></li>
<li><a href="https://speakerdeck.com/jpsim/swift-uncharted-territory">Slides</a></li>
<li><a href="https://github.com/jpsim/talks">Slides Source</a></li>
</ul>


<p>The first half of the talk covers the basic features and syntax of the language. The rest of the talk touches on some more in-depth discoveries about the runtime, introspection and how the tools work behind the scenes.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[JPSThumbnailAnnotation updated for iOS 7]]></title>
    <link href="https://jpsim.com/jpsthumbnailannotation-updated-for-ios-7/"/>
    <updated>2014-03-27T11:55:00+00:00</updated>
    <id>https://jpsim.com/jpsthumbnailannotation-updated-for-ios-7</id>
    <content type="html"><![CDATA[<p>I've just given a fresh coat of iOS7-flavoured paint to my most popular open-source library: JPSThumbnailAnnotation.</p>

<p>Check it out on <a href="https://github.com/jpsim/JPSThumbnailAnnotation">GitHub</a> or just add it to CocoaPods: <code>pod 'JPSThumbnailAnnotation'</code>.</p>

<p><img src="https://github.com/jpsim/JPSThumbnailAnnotation/raw/master/screenshots2.jpg" alt="Screenshots" /></p>

<p>I decided not to maintain the iOS 6 <em>style</em>, but iOS 6 is still supported.</p>

<p>By the way, this is what the old style looked like. It's still in git, if you need to find it for some reason.</p>

<p><img src="https://github.com/jpsim/JPSThumbnailAnnotation/raw/master/screenshots.jpg" alt="Old Screenshots" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Keyboard Layout Guide]]></title>
    <link href="https://jpsim.com/keyboard-layout-guide/"/>
    <updated>2014-03-26T14:41:00+00:00</updated>
    <id>https://jpsim.com/keyboard-layout-guide</id>
    <content type="html"><![CDATA[<p>I really like iOS 7's <code>topLayoutGuide</code> and <code>bottomLayoutGuide</code>. They're immensely useful. But in my adventures with Auto Layout, I've often wished that Apple had added a third member to this exclusive group: a sort of <code>keyboardLayoutGuide</code>.</p>

<p>It's a bit of a drag to have to set up <code>NSNotification</code> observers just to be able to keep your textfield on the screen when the keyboard barges into view. So I added a <code>keyboardLayoutGuide</code> to <code>UIViewController</code> myself. You can check it out on GitHub here: <a href="https://github.com/jpsim/JPSKeyboardLayoutGuide">jpsim/JPSKeyboardLayoutGuide</a>.</p>

<p>If you've used Apple's layout guides before, you'll know that they're actually just <code>id</code>'s that conform to the <a href="https://developer.apple.com/library/ios/documentation/uikit/reference/UILayoutSupport_Protocol/Reference/Reference.html"><code>UILayoutSupport</code> Protocol</a>. So I figured that having the guide just be a zero-sized UIView was probably the best way to go. This way, I can easily add it to the view and bind it to the keyboard frame by modifying a constraint's constant.</p>

<p>In all honesty, I dislike the inheritance approach I took here; it seems like the easy way out. I'm hoping that either myself or a contributor will have a stroke of genius and find a composition-based way to do this. Perhaps a starting point would be a category on <code>UIViewController</code> along with an associated object as the <code>keyboardLayoutGuide</code> property... But then the <code>NSNotification</code>s will be troublesome. If you have an idea, please fork and send a PR or open up an issue on <a href="https://github.com/jpsim/JPSKeyboardLayoutGuide">github</a>!</p>
]]></content>
  </entry>
  
</feed>
